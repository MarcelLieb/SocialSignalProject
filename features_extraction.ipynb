{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64db783c",
   "metadata": {},
   "source": [
    "# Test zum speichern der Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8228f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241cd55b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x212b8108210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd0db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bb3258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>video_id</th>\n",
       "      <th>segment</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>humor</th>\n",
       "      <th>coach</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baum_01_1116500_1133500_0_2000</td>\n",
       "      <td>baum_01</td>\n",
       "      <td>baum_01_1116500_1133500</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baum</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baum_01_1116500_1133500_1000_3000</td>\n",
       "      <td>baum_01</td>\n",
       "      <td>baum_01_1116500_1133500</td>\n",
       "      <td>1000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baum</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baum_01_1116500_1133500_2000_4000</td>\n",
       "      <td>baum_01</td>\n",
       "      <td>baum_01_1116500_1133500</td>\n",
       "      <td>2000</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baum</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baum_01_1116500_1133500_3000_5000</td>\n",
       "      <td>baum_01</td>\n",
       "      <td>baum_01_1116500_1133500</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baum</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baum_01_1116500_1133500_4000_6000</td>\n",
       "      <td>baum_01</td>\n",
       "      <td>baum_01_1116500_1133500</td>\n",
       "      <td>4000</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>baum</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID video_id                  segment  start  \\\n",
       "0     baum_01_1116500_1133500_0_2000  baum_01  baum_01_1116500_1133500      0   \n",
       "1  baum_01_1116500_1133500_1000_3000  baum_01  baum_01_1116500_1133500   1000   \n",
       "2  baum_01_1116500_1133500_2000_4000  baum_01  baum_01_1116500_1133500   2000   \n",
       "3  baum_01_1116500_1133500_3000_5000  baum_01  baum_01_1116500_1133500   3000   \n",
       "4  baum_01_1116500_1133500_4000_6000  baum_01  baum_01_1116500_1133500   4000   \n",
       "\n",
       "    end  humor coach partition  \n",
       "0  2000    0.0  baum     train  \n",
       "1  3000    0.0  baum     train  \n",
       "2  4000    0.0  baum     train  \n",
       "3  5000    0.0  baum     train  \n",
       "4  6000    0.0  baum     train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "cwd = Path.cwd()\n",
    "DATA_DIR = os.path.join(cwd, 'data')\n",
    "FEATURES_DIR = os.path.join(DATA_DIR, 'features')\n",
    "\n",
    "gs_df = pd.read_csv(os.path.join(DATA_DIR, 'gs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b709d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34052418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.signal import resample\n",
    "import numpy as np\n",
    "expected_sr = 16000\n",
    "\n",
    "def load_windowed_signal(file, window=3, step=.5):\n",
    "    signal, sr = librosa.load(file)\n",
    "    intermediate = int(signal.__len__() * (expected_sr / sr))\n",
    "    signal = resample(signal,intermediate)\n",
    "    windows = sliding_window_view(signal,window * expected_sr)\n",
    "    windows = windows[::int(expected_sr * step)]\n",
    "    remaining = signal.__len__() % int(expected_sr * step) + int(window * expected_sr) - int(step * expected_sr)\n",
    "    while remaining > expected_sr:\n",
    "        windows = np.concatenate((windows,[np.pad(signal[-remaining:],(0,window * expected_sr - remaining),'constant',constant_values=(0,0))]))\n",
    "        remaining -= int(step * expected_sr)\n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc3d350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fabio\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Wav2Vec2Processor\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2Model,\n",
    "    Wav2Vec2PreTrainedModel,\n",
    ")\n",
    "\n",
    "\n",
    "class RegressionHead(nn.Module):\n",
    "    r\"\"\"Classification head.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmotionModel(Wav2Vec2PreTrainedModel):\n",
    "    r\"\"\"Speech emotion classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.config = config\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = RegressionHead(config)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "    ):\n",
    "\n",
    "        outputs = self.wav2vec2(input_values)\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = torch.mean(hidden_states, dim=1)\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        return hidden_states, logits\n",
    "\n",
    "\n",
    "\n",
    "# load model from hub\n",
    "device = 'cuda'\n",
    "model_name = 'audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim'\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = EmotionModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# dummy signal\n",
    "sampling_rate = 16000\n",
    "signal = np.zeros((1, sampling_rate), dtype=np.float32)\n",
    "\n",
    "\n",
    "def process_func(\n",
    "    x: np.ndarray,\n",
    "    sampling_rate: int,\n",
    "    embeddings: bool = False,\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"Predict emotions or extract embeddings from raw audio signal.\"\"\"\n",
    "\n",
    "    # run through processor to normalize signal\n",
    "    # always returns a batch, so we just get the first entry\n",
    "    # then we put it on the device\n",
    "    y = processor(x, sampling_rate=sampling_rate)\n",
    "    y = y['input_values']\n",
    "    y = np.array(y)\n",
    "    #y = y.reshape(1, -1)\n",
    "    y = torch.from_numpy(y).to(device)\n",
    "    # run through model\n",
    "    with torch.no_grad():\n",
    "        y = model(y)[0 if embeddings else 1]\n",
    "\n",
    "    # convert to numpy\n",
    "    y = y.detach().cpu().numpy()\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "#print(process_func(signal, sampling_rate))\n",
    "#  Arousal    dominance valence\n",
    "# [[0.5460754  0.6062266  0.40431657]]\n",
    "\n",
    "#print(process_func(signal, sampling_rate, embeddings=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbff427d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.cuda.memory.empty_cache() -> None>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29c04300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2711, 8)\n",
      "0.0%\n",
      "2.3607524898561416%\n",
      "4.352637403172261%\n",
      "6.565842862412394%\n",
      "9.221689413500552%\n",
      "11.287347842124678%\n",
      "13.463666543710808%\n",
      "16.045739579490963%\n",
      "17.078568793803026%\n",
      "19.402434526005162%\n",
      "20.582810770933236%\n",
      "22.50092216894135%\n",
      "24.52969383991147%\n",
      "25.710070084839543%\n",
      "26.6691257838436%\n",
      "27.443747694577645%\n",
      "28.255256362965696%\n",
      "30.13648100331981%\n",
      "33.75138325341202%\n",
      "36.00147547030616%\n",
      "37.47694577646625%\n",
      "37.58760604942825%\n",
      "38.952416082626335%\n",
      "41.57137587606049%\n",
      "44.374769457764664%\n",
      "45.186278126152715%\n",
      "49.61268904463298%\n",
      "50.719291774253044%\n",
      "51.6783474732571%\n",
      "53.3382515676872%\n",
      "55.99409811877536%\n",
      "58.09664330505348%\n",
      "60.16230173367761%\n",
      "61.08447067502767%\n",
      "62.04352637403172%\n",
      "62.744374769457764%\n",
      "63.77720398376983%\n",
      "64.81003319808188%\n",
      "68.68314275175211%\n",
      "70.74880118037625%\n",
      "72.55625230542235%\n",
      "74.17926964219845%\n",
      "77.16709701217263%\n",
      "80.22869789745481%\n",
      "85.39284396901512%\n",
      "87.67982294356327%\n",
      "90.33566949465143%\n",
      "93.76613795647363%\n",
      "97.71302102545187%\n"
     ]
    }
   ],
   "source": [
    "# load features:\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "i = -1\n",
    "cwd = Path.cwd()\n",
    "DATA_DIR = os.path.join(cwd, 'data')\n",
    "gs_df = pd.read_csv(os.path.join(DATA_DIR, 'gs.csv'))\n",
    "\n",
    "# single load of coaches, because the programm crashed and loading old coaches again would have aken too much time\n",
    "gs_df = gs_df[gs_df.coach=='breitenreiter']\n",
    "last_segment = \"\"\n",
    "print(gs_df.shape)\n",
    "len_df = gs_df.shape[0]\n",
    "SOUND_DIR = os.path.join(cwd, 'audio')\n",
    "for _, row in gs_df.iterrows():\n",
    "    i += 1\n",
    "    if last_segment == row[\"segment\"]:\n",
    "        continue\n",
    "    print(str((i*100)/len_df) + \"%\")\n",
    "    last_segment = row[\"segment\"]\n",
    "    file_sound = f'{SOUND_DIR}/{row[\"coach\"]}/{row[\"video_id\"]}/{row[\"segment\"]}.wav'\n",
    "    sound_array = load_windowed_signal(file_sound, window=3, step=.5)\n",
    "    save = []\n",
    "    i_inner = 0\n",
    "    \n",
    "    # pushung chunks of data to the Grafics card\n",
    "    array_part_size = 90\n",
    "    for i_in in range(math.ceil(sound_array.shape[0]/array_part_size)):\n",
    "        part_sound = sound_array[array_part_size*i_in:array_part_size*(i_in+1)]\n",
    "        part_process = process_func(part_sound, expected_sr, embeddings=True)\n",
    "        if save.__len__() == 0:\n",
    "            save = part_process\n",
    "        else:\n",
    "            save = np.append(part_process, save, axis=0)\n",
    "    \n",
    "    timestamps = list(range(0, sound_array.__len__()*500, 500))\n",
    "    dic = {'timestamps': timestamps}\n",
    "    save = save.transpose()\n",
    "    i_inner = 1\n",
    "    for embed in save:\n",
    "        dic[str(i_inner)] = embed\n",
    "        i_inner += 1     \n",
    "    df_features = pd.DataFrame(dic)\n",
    "    df_features.to_csv(f'{SOUND_DIR}/features/{row[\"coach\"]}/{row[\"segment\"]}.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0810ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['baum', 'breitenreiter', 'hasenhuttl', 'hecking', 'herrlich',\n",
       "       'kovac', 'nagelsmann', 'schwarz', 'streich', 'tedesco'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see the coaches\n",
    "gs_df = pd.read_csv(os.path.join(DATA_DIR, 'gs.csv'))\n",
    "gs_df['coach'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
